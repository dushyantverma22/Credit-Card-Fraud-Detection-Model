{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355c3deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import calendar\n",
    "from typing import Dict, Any\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0732b5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb56910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def data_preprocessing(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocesses transaction data for fraud detection analysis.\n",
    "    \n",
    "    Args:\n",
    "        df: Raw transaction DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed DataFrame with engineered features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Helper functions\n",
    "    def create_amount_bucket(x: float) -> str:\n",
    "        \"\"\"Categorize transaction amounts into buckets\"\"\"\n",
    "        if x <= 5.00:\n",
    "            return \"less than 5 dollar\"\n",
    "        elif 5.00 < x <= 10.00:\n",
    "            return \"b/w 5 to 10 dollar\"\n",
    "        elif 10.00 < x <= 40.00:\n",
    "            return \"b/w 10 to 40 dollar\"\n",
    "        elif 40.00 < x <= 60.00:\n",
    "            return \"b/w 40 to 60 dollar\"\n",
    "        elif 60.00 < x <= 80.00:\n",
    "            return \"b/w 60 to 80 dollar\"\n",
    "        elif 80.00 < x <= 150.00:\n",
    "            return \"b/w 80 to 150 dollar\"\n",
    "        else:\n",
    "            return \"more than 150 dollar\"\n",
    "    \n",
    "    def city_pop_cat(x: float) -> str:\n",
    "        \"\"\"Categorize city population\"\"\"\n",
    "        if x <= 1000.00:\n",
    "            return \"Low_pop\"\n",
    "        elif 1000.00 < x <= 10000.00:\n",
    "            return \"Medium_pop\"\n",
    "        else:\n",
    "            return \"High_pop\"\n",
    "    \n",
    "    def age_bkt(x: int) -> str:\n",
    "        \"\"\"Categorize customer age\"\"\"\n",
    "        if x <= 25:\n",
    "            return \"less than 25\"\n",
    "        elif 25 < x <= 40:\n",
    "            return \"b/w 25 to 40\"\n",
    "        elif 40 < x <= 60:\n",
    "            return \"b/w 40 to 60\"\n",
    "        else:\n",
    "            return \"more than 60\"\n",
    "    \n",
    "    # 1. Amount bucketing\n",
    "    df[\"amount_bkt\"] = df[\"amt\"].apply(create_amount_bucket)\n",
    "    \n",
    "    # 2. Geographical features\n",
    "    df['latitudinal_distance'] = abs(round(df['merch_lat'] - df['lat'], 3))\n",
    "    df['longitudinal_distance'] = abs(round(df['merch_long'] - df['long'], 3))\n",
    "    \n",
    "    # 3. Population categorization\n",
    "    df[\"population_bkt\"] = df[\"city_pop\"].apply(city_pop_cat)\n",
    "    \n",
    "    # 4. Date/time features\n",
    "    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "    df['trans_date'] = df['trans_date_trans_time'].dt.strftime('%Y-%m-%d')\n",
    "    df['trans_date'] = pd.to_datetime(df['trans_date'])\n",
    "    \n",
    "    # 5. Age calculation\n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    df['age'] = (df['trans_date'] - df['dob']).dt.days / 365.25\n",
    "    df['age'] = df['age'].round(0).astype(int)\n",
    "    df[\"age_bkt\"] = df[\"age\"].apply(age_bkt)\n",
    "    \n",
    "    # 6. Time features\n",
    "    df['trans_month'] = df['trans_date_trans_time'].dt.month\n",
    "    df['Month_name'] = df['trans_month'].apply(lambda x: calendar.month_abbr[x])\n",
    "    df['transaction_time'] = df['trans_date_trans_time'].dt.time\n",
    "    \n",
    "    # 7. Time buckets\n",
    "    bins = [0, 6, 12, 18, 24]\n",
    "    labels = ['12AM-6AM', '6AM-12PM', '12PM-6PM', '6PM-12AM']\n",
    "    df['time_bucket'] = pd.cut(\n",
    "        df['trans_date_trans_time'].dt.hour,\n",
    "        bins=bins,\n",
    "        labels=labels,\n",
    "        right=False,\n",
    "        include_lowest=True\n",
    "    )\n",
    "    \n",
    "    # 8. Gender encoding\n",
    "    df[\"gender_encod\"] = df[\"gender\"].apply(lambda x: 1 if x == \"M\" else 0)\n",
    "    \n",
    "    # 9. Select final columns\n",
    "    final_columns = [\n",
    "        \"trans_num\", \"trans_date\", \"time_bucket\", \"cc_num\", \"amount_bkt\",\n",
    "        \"category\", \"gender\", \"state\", \"latitudinal_distance\",\n",
    "        \"longitudinal_distance\", \"population_bkt\", \"age\", \"age_bkt\",\n",
    "        \"gender_encod\", \"is_fraud\"\n",
    "    ]\n",
    "    \n",
    "    return df[final_columns]\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "# processed_df = data_preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607c3e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from typing import Tuple\n",
    "\n",
    "def preprocess_and_predict(raw_data: pd.DataFrame, model_path: str) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Complete pipeline from raw data to predictions:\n",
    "    1. Preprocesses the data\n",
    "    2. Encodes categorical features\n",
    "    3. Loads trained model\n",
    "    4. Generates predictions\n",
    "    \n",
    "    Args:\n",
    "        raw_data: Raw transaction DataFrame\n",
    "        model_path: Path to saved model (.pkl or .joblib)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple containing (processed_features, predictions)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Data Preprocessing\n",
    "    processed_data = data_preprocessing(raw_data)\n",
    "    \n",
    "    # 2. Feature Encoding\n",
    "    cat_cols = ['time_bucket', 'category', 'amount_bkt', 'population_bkt', 'age_bkt']\n",
    "    drop_cols = cat_cols + [\"trans_date\", \"cc_num\", \"gender\", \"state\", \"age\", 'trans_num']\n",
    "    \n",
    "    # Initialize and fit encoder\n",
    "    encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "    X_encoded = encoder.fit_transform(processed_data[cat_cols])\n",
    "    encoded_feat_names = encoder.get_feature_names_out(cat_cols)\n",
    "    \n",
    "    # Create encoded DataFrame\n",
    "    encoded_df = pd.DataFrame(X_encoded, columns=encoded_feat_names, index=processed_data.index)\n",
    "    \n",
    "    # Merge with remaining features\n",
    "    data_processed = processed_data.drop(columns=drop_cols)\n",
    "    final_features = pd.concat([data_processed, encoded_df], axis=1)\n",
    "    \n",
    "    # Ensure consistent column order with training data\n",
    "    expected_columns = [\n",
    "        'latitudinal_distance', 'longitudinal_distance', 'gender_encod',\n",
    "        'time_bucket_6AM-12PM', 'time_bucket_12PM-6PM', 'time_bucket_6PM-12AM',\n",
    "        'category_entertainment', 'category_food_dining', 'category_gas_transport',\n",
    "        'category_grocery_net', 'category_grocery_pos', 'category_health_fitness',\n",
    "        'category_home', 'category_kids_pets', 'category_misc_net',\n",
    "        'category_misc_pos', 'category_personal_care', 'category_shopping_net',\n",
    "        'category_shopping_pos', 'category_travel', 'amount_bkt_b/w 5 to 10 dollar',\n",
    "        'amount_bkt_b/w 10 to 40 dollar', 'amount_bkt_b/w 40 to 60 dollar',\n",
    "        'amount_bkt_b/w 60 to 80 dollar', 'amount_bkt_b/w 80 to 150 dollar',\n",
    "        'amount_bkt_more than 150 dollar', 'population_bkt_Medium_pop',\n",
    "        'population_bkt_High_pop', 'age_bkt_b/w 25 to 40', 'age_bkt_b/w 40 to 60',\n",
    "        'age_bkt_more than 60'\n",
    "    ]\n",
    "    \n",
    "    # Reindex to ensure correct column order\n",
    "    final_features = final_features.reindex(columns=expected_columns, fill_value=0)\n",
    "    \n",
    "    # 3. Load Model\n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "        print(\"Model loaded successfully\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading model: {str(e)}\")\n",
    "    \n",
    "    # 4. Generate Predictions\n",
    "    predictions = model.predict(final_features)\n",
    "    prediction_probs = model.predict_proba(final_features)[:, 1]  # Fraud probabilities\n",
    "    \n",
    "    # Add predictions to DataFrame\n",
    "    processed_data['predicted_fraud'] = predictions\n",
    "    processed_data['fraud_probability'] = prediction_probs\n",
    "    \n",
    "    return processed_data, predictions\n",
    "\n",
    "# Example Usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Load raw data\n",
    "    raw_df = pd.read_csv('transactions.csv')\n",
    "    \n",
    "    # Run pipeline\n",
    "    try:\n",
    "        results_df, predictions = preprocess_and_predict(\n",
    "            raw_data=raw_df,\n",
    "            model_path='fraud_detection_model.joblib'\n",
    "        )\n",
    "        \n",
    "        print(\"\\nPredictions generated successfully:\")\n",
    "        print(results_df[['trans_num', 'predicted_fraud', 'fraud_probability']].head())\n",
    "        \n",
    "        # Save results\n",
    "        results_df.to_csv('processed_transactions_with_predictions.csv', index=False)\n",
    "        print(\"\\nResults saved to 'processed_transactions_with_predictions.csv'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Pipeline failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f841d74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
